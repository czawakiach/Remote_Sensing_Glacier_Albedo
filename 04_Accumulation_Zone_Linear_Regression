import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.impute import SimpleImputer
from sklearn.model_selection import GridSearchCV
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

def standardize_station_names(df):
    """
    Standardize station names to AWS_H4, AWS_H9, AWS_WRN format
    """
    station_mapping = {
        'hans4': 'AWS_H4',
        'hans9': 'AWS_H9',
        'werenskiold': 'AWS_WRN',
        'werenskioldbreen': 'AWS_WRN'
    }
    
    if 'station' in df.columns:
        df['station'] = df['station'].map(lambda x: station_mapping.get(x.lower(), x))
    
    return df

def load_and_combine_data(base_path, train_files, test_files):
    """
    Load and combine data separately for training and testing sets
    """
    base_dir = Path(base_path)
    
    # Load training data
    train_dfs = []
    for file_name in train_files:
        file_path = base_dir / file_name
        df = pd.read_csv(file_path)
        df = standardize_station_names(df)
        print(f"Loaded training: {file_name} ({len(df)} records)")
        train_dfs.append(df)
    
    # Load testing data
    test_dfs = []
    for file_name in test_files:
        file_path = base_dir / file_name
        df = pd.read_csv(file_path)
        df = standardize_station_names(df)
        print(f"Loaded testing: {file_name} ({len(df)} records)")
        test_dfs.append(df)
    
    return pd.concat(train_dfs, ignore_index=True), pd.concat(test_dfs, ignore_index=True)

def filter_season(df, year_col='year', doy_col='day_of_year'):
    """
    Filter dataframe to keep data from April 8th to September 4th
    """
    spring_start_doy = 98   # April 8th
    end_date_doy = 247      # September 4th
    
    season_mask = (df[doy_col] >= spring_start_doy) & (df[doy_col] <= end_date_doy)
    return df[season_mask].copy()

def prepare_data(base_path, train_files, test_files):
    """
    Load and prepare data for training (2010 hans4/hans9, 2012 werenskiold) 
    and testing (2011 all stations)
    """
    # Load and combine training and testing data separately
    train_df, test_df = load_and_combine_data(base_path, train_files, test_files)
    
    # Filter for extended season
    train_df = filter_season(train_df)
    test_df = filter_season(test_df)
    
    # Define feature columns
    feature_cols = ['TC', 'PDD', 'day_of_year', 'snowfall_probability']
    
    print(f"\nUsing features: {feature_cols}")
    
    # Check if columns exist
    missing_train = [col for col in feature_cols + ['albedo'] if col not in train_df.columns]
    missing_test = [col for col in feature_cols + ['albedo'] if col not in test_df.columns]
    
    if missing_train:
        print(f"Warning: Missing columns in training data: {missing_train}")
        print(f"Available columns: {list(train_df.columns)}")
    
    if missing_test:
        print(f"Warning: Missing columns in test data: {missing_test}")
        print(f"Available columns: {list(test_df.columns)}")
    
    # Prepare training data
    X_train = train_df[feature_cols]
    y_train = train_df['albedo']
    
    # Prepare testing data
    X_test = test_df[feature_cols]
    y_test = test_df['albedo']
    
    # Handle missing values in features
    feature_imputer = SimpleImputer(strategy='mean')
    X_train_clean = pd.DataFrame(
        feature_imputer.fit_transform(X_train),
        columns=X_train.columns,
        index=X_train.index
    )
    X_test_clean = pd.DataFrame(
        feature_imputer.transform(X_test),
        columns=X_test.columns,
        index=X_test.index
    )
    
    # Handle missing values in target
    target_imputer = SimpleImputer(strategy='mean')
    y_train_clean = pd.Series(
        target_imputer.fit_transform(y_train.values.reshape(-1, 1)).ravel(),
        index=y_train.index
    )
    y_test_clean = pd.Series(
        target_imputer.transform(y_test.values.reshape(-1, 1)).ravel(),
        index=y_test.index
    )
    
    # Print information about missing values
    print("\nMissing values summary before imputation:")
    print("\nFeatures (X_train):")
    print(X_train.isna().sum())
    print("\nTarget (y_train):")
    print(f"Missing values in y_train: {y_train.isna().sum()}")
    
    print(f"\nData summary:")
    print(f"Training samples: {len(X_train_clean)}")
    print(f"Testing samples: {len(X_test_clean)}")
    
    return X_train_clean, X_test_clean, y_train_clean, y_test_clean, test_df

def train_and_evaluate_mlp(X_train, X_test, y_train, y_test, test_data):
    """
    Train MLP Regressor model and evaluate performance
    """
    # Scale features for better MLP performance
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Define MLP model
    mlp = MLPRegressor(
        hidden_layer_sizes=(100, 50),  # Two hidden layers with 100 and 50 neurons
        activation='relu',             # ReLU activation function
        solver='adam',                 # Adam optimizer
        alpha=0.0001,                  # L2 regularization term
        max_iter=1000,                 # Maximum number of iterations
        early_stopping=True,           # Use early stopping
        validation_fraction=0.1,       # Fraction of training data for validation
        random_state=42                # For reproducibility
    )
    
    # Train model
    print("Training MLP neural network...")
    mlp.fit(X_train_scaled, y_train)
    print(f"Training converged in {mlp.n_iter_} iterations")
    
    # Make predictions
    y_pred = mlp.predict(X_test_scaled)
    
    # Calculate residuals for uncertainty estimation
    y_train_pred = mlp.predict(X_train_scaled)
    train_residuals = y_train - y_train_pred
    residual_std = np.std(train_residuals)
    
    # Calculate overall metrics
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    
    # Calculate station-specific metrics
    station_metrics = {}
    for station in test_data['station'].unique():
        mask = test_data['station'] == station
        station_y_test = y_test[mask]
        station_y_pred = y_pred[mask]
        
        station_metrics[station] = {
            'R2': r2_score(station_y_test, station_y_pred),
            'RMSE': np.sqrt(mean_squared_error(station_y_test, station_y_pred))
        }
    
    # For feature importance, use permutation importance or other approaches
    feature_importance = {}
    normalized_importance = {}
    
    return mlp, scaler, y_pred, r2, rmse, station_metrics, feature_importance, normalized_importance, residual_std

def calculate_feature_importance(model, X_test_scaled, y_test, feature_names):
    """
    Calculate feature importance using permutation importance
    """
    from sklearn.inspection import permutation_importance
    
    print("Calculating permutation importance (this may take a moment)...")
    
    # Calculate permutation importance
    perm_importance = permutation_importance(model, X_test_scaled, y_test, n_repeats=10, random_state=42)
    
    # Store feature importance
    feature_importance = dict(zip(feature_names, perm_importance.importances_mean))
    
    # Normalize importance
    total_importance = sum(perm_importance.importances_mean)
    if total_importance > 0:
        normalized_importance = {feature: importance / total_importance 
                                for feature, importance in feature_importance.items()}
    else:
        normalized_importance = {feature: 0 for feature in feature_names}
    
    return feature_importance, normalized_importance

def plot_predicted_vs_measured(y_test, y_pred, test_data, rmse):
    """
    Create scatter plot of predicted vs measured albedo values with error information
    """
    plt.figure(figsize=(12, 8))
    
    # Define colors for stations
    station_colors = {
        'AWS_H4': '#1f77b4',
        'AWS_H9': '#ff7f0e', 
        'AWS_WRN': '#2ca02c'
    }
    
    # Plot by station
    for station in sorted(test_data['station'].unique()):
        mask = test_data['station'] == station
        color = station_colors.get(station, None)
        plt.scatter(y_test[mask], y_pred[mask], alpha=0.6, label=station, 
                   s=50, color=color, edgecolors='white', linewidth=0.5)
    
    # Add perfect prediction line
    line = np.linspace(min(y_test), max(y_test), 100)
    plt.plot(line, line, 'k--', alpha=0.5, linewidth=2, label='1:1 line')
    
    # Add RMSE as shaded region around 1:1 line
    plt.fill_between(line, line - rmse, line + rmse, alpha=0.2, color='gray', 
                     label=f'±RMSE ({rmse:.2f})')
    
    plt.xlabel('Measured Albedo', fontsize=12, fontweight='bold')
    plt.ylabel('Predicted Albedo', fontsize=12, fontweight='bold')
    plt.title('MLP Neural Network: Predicted vs Measured Albedo (2011 Test Data)', 
              fontsize=14, fontweight='bold')
    plt.legend(fontsize=10, loc='upper left')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

def plot_feature_importance(feature_importance):
    """
    Create bar plot of feature importance
    """
    plt.figure(figsize=(10, 6))
    importance_df = pd.DataFrame({
        'Feature': feature_importance.keys(),
        'Importance': feature_importance.values()
    })
    importance_df = importance_df.sort_values('Importance', ascending=True)
    
    plt.barh(importance_df['Feature'], importance_df['Importance'])
    plt.xlabel('Permutation Importance', fontsize=12, fontweight='bold')
    plt.title('MLP Neural Network Feature Importance', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

def plot_station_time_series(station_name, test_data, y_test, y_pred, residual_std):
    """
    Plot time series comparison for a specific station with uncertainty bands
    """
    mask = test_data['station'] == station_name
    
    station_data = test_data[mask]
    station_measured = y_test[mask]
    station_predicted = y_pred[mask]
    
    plt.figure(figsize=(14, 7))
    
    # Sort by day of year
    sort_idx = np.argsort(station_data['day_of_year'])
    days = station_data['day_of_year'].values[sort_idx]
    measured = station_measured.values[sort_idx]
    predicted = station_predicted[sort_idx]
    
    # Calculate uncertainty bounds (±1 standard deviation of residuals)
    upper_bound = predicted + residual_std
    lower_bound = predicted - residual_std
    
    # Plot uncertainty band first (so it's in the background)
    plt.fill_between(days, lower_bound, upper_bound, 
                     alpha=0.3, color='gray', 
                     label=f'Uncertainty band (±{residual_std:.2f})')
    
    # Plot the lines
    plt.plot(days, measured, 'b-', label='Measured', linewidth=2.5, marker='o', 
             markersize=4, markevery=5)
    plt.plot(days, predicted, 'r--', label='Predicted', linewidth=2.5, marker='s', 
             markersize=4, markevery=5)
    
    plt.xlabel('Day of Year', fontsize=12, fontweight='bold')
    plt.ylabel('Albedo', fontsize=12, fontweight='bold')
    plt.title(f'MLP Neural Network: Albedo Time Series for {station_name} (2011)', 
              fontsize=14, fontweight='bold')
    plt.legend(fontsize=11, loc='best')
    plt.grid(True, alpha=0.3)
    plt.ylim([0, 1])
    plt.tight_layout()
    plt.show()

def optimize_mlp_hyperparameters(X_train, y_train):
    """
    Perform grid search to find optimal MLP hyperparameters
    """
    print("Performing hyperparameter optimization...")
    
    # Scale features for better MLP performance
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    
    # Define parameter grid (simplified for faster execution)
    param_grid = {
        'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],
        'activation': ['relu', 'tanh'],
        'alpha': [0.0001, 0.001],
        'learning_rate_init': [0.001, 0.01]
    }
    
    # Create GridSearchCV object
    grid_search = GridSearchCV(
        MLPRegressor(max_iter=1000, early_stopping=True, random_state=42),
        param_grid,
        cv=3,
        scoring='neg_mean_squared_error',
        n_jobs=-1,
        verbose=1
    )
    
    # Perform grid search
    grid_search.fit(X_train_scaled, y_train)
    
    # Get best parameters
    best_params = grid_search.best_params_
    
    return best_params, scaler

def main():
    print("="*60)
    print("MLP NEURAL NETWORK ALBEDO PREDICTION MODEL")
    print("="*60)
    
    # Configuration - UPDATE THIS PATH
    base_path = r"C:\Users\PC\PhD\2024_Hans_data\Albedo_Glacier_ML\processed_data\daily_ready\processed_probability"
    
    # Define training and testing file paths - Hans9 only (as per original)
    train_files = [
        "hans9_2010_snowfall_probability_clean.csv",
    ]
    
    test_files = [
        "hans9_2011_snowfall_probability_clean.csv"
    ]
    
    print(f"Base path: {base_path}")
    print(f"Training files: {train_files}")
    print(f"Testing files: {test_files}")
    
    # Load and prepare data
    X_train_clean, X_test_clean, y_train_clean, y_test_clean, test_data_clean = prepare_data(
        base_path, train_files, test_files
    )
    
    # Train and evaluate model
    print("\nTraining MLP neural network model...")
    mlp, scaler, y_pred, r2, rmse, station_metrics, _, _, residual_std = train_and_evaluate_mlp(
        X_train_clean, X_test_clean, y_train_clean, y_test_clean, test_data_clean
    )
    
    # Calculate feature importance
    print("\nCalculating feature importance...")
    X_test_scaled = scaler.transform(X_test_clean)
    feature_importance, normalized_importance = calculate_feature_importance(
        mlp, X_test_scaled, y_test_clean, X_train_clean.columns
    )
    
    # Print results
    print("\nExtended Season MLP Neural Network Results (April 8 - September 4)")
    print("-" * 60)
    print(f"Overall Model Performance:")
    print(f"R² Score: {r2:.2f}")
    print(f"RMSE: {rmse:.2f}")
    print(f"Residual Std Dev: {residual_std:.2f}")
    print(f"Training iterations: {mlp.n_iter_}")
    print("\nStation-specific Performance:")
    for station in sorted(station_metrics.keys()):
        metrics = station_metrics[station]
        print(f"\n{station}:")
        print(f"  R² Score: {metrics['R2']:.2f}")
        print(f"  RMSE: {metrics['RMSE']:.2f}")
    print("\nFeature Importance (Permutation):")
    for feature in feature_importance:
        print(f"{feature}:")
        print(f"  Importance: {feature_importance[feature]:.4f}")
        print(f"  Normalized Importance: {normalized_importance[feature]:.2f}")
    
    # Analyze feature dominance
    snowfall_importance = normalized_importance.get('snowfall_probability', 0)
    thermal_features = ['TC', 'PDD']
    thermal_importance = sum(normalized_importance.get(f, 0) for f in thermal_features)
    seasonal_importance = normalized_importance.get('day_of_year', 0)
    
    print(f"\nProcess Dominance Analysis (Neural Network):")
    print(f"Snowfall processes: {snowfall_importance:.1%}")
    print(f"Thermal processes: {thermal_importance:.1%}")
    print(f"Seasonal patterns: {seasonal_importance:.1%}")
    
    if snowfall_importance > max(thermal_importance, seasonal_importance):
        print("→ SNOWFALL DOMINANCE detected by neural network")
    elif thermal_importance > max(snowfall_importance, seasonal_importance):
        print("→ THERMAL DOMINANCE detected by neural network")
    else:
        print("→ SEASONAL DOMINANCE detected by neural network")
    
    # Create plots
    plot_predicted_vs_measured(y_test_clean, y_pred, test_data_clean, rmse)
    plot_feature_importance(feature_importance)
    
    # Create individual station time series plots with uncertainty bands
    for station in sorted(test_data_clean['station'].unique()):
        plot_station_time_series(station, test_data_clean, y_test_clean, y_pred, residual_std)

if __name__ == "__main__":
    main()
