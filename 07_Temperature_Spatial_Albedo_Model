import numpy as np
import pandas as pd
import rasterio
from rasterio.transform import from_bounds
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
from datetime import datetime, timedelta
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
import warnings
warnings.filterwarnings('ignore')

class SpatialAlbedoModelTemperature:
    """
    Spatial albedo modeling using TEMPERATURE-DOMINATED approach.
    Emphasizes daily positive temperature and thermal processes over precipitation.
    Uses glacier-specific AWS stations to avoid temperature inversion artifacts.
    """
    
    def __init__(self, dem_paths, aws_data_paths, station_elevations, glacier_to_stations):
        """
        Initialize the spatial albedo model (Temperature-Dominated version)
        
        Parameters:
        dem_paths (dict): Paths to DEM files for each glacier
        aws_data_paths (dict): Paths to AWS station data files  
        station_elevations (dict): Elevation of each AWS station in meters
        glacier_to_stations (dict): Mapping of glacier names to their AWS stations
        """
        self.dem_paths = dem_paths
        self.aws_data_paths = aws_data_paths
        self.station_elevations = station_elevations
        self.glacier_to_stations = glacier_to_stations
        
        # Storage for loaded data and trained models
        self.dems = {}
        self.aws_data = {}
        self.model = None
        self.imputer = None
        
    def load_dems(self):
        """Load Digital Elevation Model data for each glacier"""
        for glacier_name, dem_path in self.dem_paths.items():
            try:
                with rasterio.open(dem_path) as src:
                    elevation = src.read(1)
                    transform = src.transform
                    crs = src.crs
                    
                    # Handle NoData values
                    elevation = elevation.astype(float)
                    elevation[elevation <= -9999] = np.nan
                    
                    # Create coordinate arrays
                    height, width = elevation.shape
                    cols, rows = np.meshgrid(np.arange(width), np.arange(height))
                    xs, ys = rasterio.transform.xy(transform, rows, cols)
                    
                    # Store DEM data
                    self.dems[glacier_name] = {
                        'elevation': elevation,
                        'transform': transform,
                        'crs': crs,
                        'x_coords': np.array(xs),
                        'y_coords': np.array(ys),
                        'shape': elevation.shape
                    }
                    
                print(f"Loaded DEM for {glacier_name}: {elevation.shape}")
                
                # Report statistics
                valid_elevation = elevation[~np.isnan(elevation)]
                if len(valid_elevation) > 0:
                    print(f"  Elevation range: {np.min(valid_elevation):.1f} - {np.max(valid_elevation):.1f} m")
                    print(f"  Valid pixels: {len(valid_elevation):,} / {elevation.size:,}")
                
            except Exception as e:
                print(f"Error loading DEM for {glacier_name}: {e}")
    
    def load_aws_data(self):
        """Load Automatic Weather Station data"""
        for station_name, data_path in self.aws_data_paths.items():
            try:
                df = pd.read_csv(data_path)
                df['date'] = pd.to_datetime(df['date'])
                
                # Remove rows with missing albedo
                initial_len = len(df)
                df = df.dropna(subset=['albedo'])
                final_len = len(df)
                
                self.aws_data[station_name] = df
                print(f"Loaded AWS data for {station_name}: {final_len:,} records")
                if initial_len != final_len:
                    print(f"  Removed {initial_len-final_len} records with missing albedo")
                print(f"  Date range: {df['date'].min()} to {df['date'].max()}")
                
                # Check for required columns
                required_cols = ['date', 'albedo', 'daily_positive_temp', 'PDD', 'snowfall_probability', 'day_of_year']
                missing_cols = [col for col in required_cols if col not in df.columns]
                if missing_cols:
                    print(f"  Warning: Missing columns in {station_name}: {missing_cols}")
                
            except Exception as e:
                print(f"Error loading AWS data for {station_name}: {e}")
    
    def calculate_topographic_variables(self, glacier_name):
        """Calculate slope and aspect from DEM"""
        dem_data = self.dems[glacier_name]
        elevation = dem_data['elevation']
        
        dy, dx = np.gradient(elevation)
        slope = np.arctan(np.sqrt(dx**2 + dy**2)) * 180 / np.pi
        aspect = np.arctan2(-dx, dy) * 180 / np.pi
        aspect[aspect < 0] += 360
        
        self.dems[glacier_name]['slope'] = slope
        self.dems[glacier_name]['aspect'] = aspect
        
        print(f"Calculated topographic variables for {glacier_name}")
        return slope, aspect
    
    def train_model_from_data(self):
        """
        Train linear regression model using TEMPERATURE-DOMINATED approach.
        Features emphasize thermal processes (daily_positive_temp, PDD) over precipitation.
        """
        # Combine data from all AWS stations
        all_data = []
        for station_name, df in self.aws_data.items():
            station_df = df.copy()
            station_df['elevation'] = self.station_elevations[station_name]
            all_data.append(station_df)
        
        combined_df = pd.concat(all_data, ignore_index=True)
        combined_df = combined_df.dropna(subset=['albedo'])
        
        print(f"Training dataset: {len(combined_df):,} records from {len(self.aws_data)} stations")
        
        # TEMPERATURE-DOMINATED FEATURES (matching the temperature model from earlier)
        # Order emphasizes thermal processes
        feature_cols = ['day_of_year', 'daily_positive_temp', 'PDD', 'snowfall_probability', 'elevation']
        
        # Check for missing features
        missing_features = [col for col in feature_cols if col not in combined_df.columns]
        if missing_features:
            print(f"Warning: Missing feature columns: {missing_features}")
            feature_cols = [col for col in feature_cols if col in combined_df.columns]
            print(f"Using available features: {feature_cols}")
        
        X = combined_df[feature_cols]
        y = combined_df['albedo']
        
        # Handle missing values
        self.imputer = SimpleImputer(strategy='mean')
        X_clean = self.imputer.fit_transform(X)
        
        # Train linear regression model
        self.model = LinearRegression()
        self.model.fit(X_clean, y)
        
        self.feature_names = feature_cols
        
        # Report performance
        r2_score = self.model.score(X_clean, y)
        print(f"Trained TEMPERATURE-DOMINATED linear regression model:")
        print(f"  Features: {feature_cols}")
        print(f"  R² score: {r2_score:.2f}")
        
        # Calculate feature importance
        coefficients = dict(zip(feature_cols, self.model.coef_))
        print(f"  Model coefficients: {coefficients}")
        print(f"  Model intercept: {self.model.intercept_:.2f}")
        
        # Analyze thermal vs precipitation dominance
        abs_coeffs = np.abs(self.model.coef_)
        normalized_importance = abs_coeffs / np.sum(abs_coeffs)
        importance_dict = dict(zip(feature_cols, normalized_importance))
        
        thermal_importance = sum(importance_dict.get(f, 0) for f in ['daily_positive_temp', 'PDD'])
        precip_importance = importance_dict.get('snowfall_probability', 0)
        
        print(f"\n  Process Dominance:")
        print(f"    Thermal processes (daily_positive_temp + PDD): {thermal_importance:.1%}")
        print(f"    Precipitation processes (snowfall_probability): {precip_importance:.1%}")
        
        if thermal_importance > precip_importance:
            print(f"    → THERMAL DOMINANCE confirmed in spatial model")
        
        return self.model
    
    def interpolate_meteorological_variables(self, glacier_name, target_date, lapse_rate_temp=-0.0053):
        """
        Interpolate meteorological variables from glacier-specific AWS station.
        Uses only one station per glacier to avoid temperature inversion issues.
        
        Parameters:
        glacier_name (str): Name of target glacier
        target_date (datetime): Date for interpolation
        lapse_rate_temp (float): Temperature lapse rate (°C/m) = -0.53°C/100m
        
        Returns:
        dict: Interpolated meteorological variables on glacier grid
        """
        dem_data = self.dems[glacier_name]
        elevation_grid = dem_data['elevation']
        
        # Get glacier-specific stations
        allowed_stations = self.glacier_to_stations.get(glacier_name, [])
        print(f"  Using stations for {glacier_name}: {allowed_stations}")
        
        # Extract station data for target date
        station_data_list = []
        
        for station_name in allowed_stations:
            if station_name in self.aws_data:
                station_df = self.aws_data[station_name]
                
                station_df['date_only'] = station_df['date'].dt.date
                target_date_only = target_date.date()
                date_mask = station_df['date_only'] == target_date_only
                
                if date_mask.any():
                    station_data = station_df[date_mask].iloc[0]
                    station_elevation = self.station_elevations[station_name]
                    station_data_list.append((station_name, station_data, station_elevation))
                    print(f"  Found data for {station_name} on {target_date_only}")
                else:
                    print(f"  No data for {station_name} on {target_date_only}")
        
        if not station_data_list:
            print(f"  No station data available for {target_date}")
            return None
        
        # Use the first (and typically only) station for this glacier
        station_name, station_data, station_elevation = station_data_list[0]
        
        interpolated_vars = {}
        
        # Calculate daily_positive_temp field (temperature-based, with lapse rate)
        # Daily positive temp is derived from temperature, so apply lapse rate
        if 'daily_positive_temp' in station_data:
            station_daily_positive_temp = station_data['daily_positive_temp']
            # Apply elevation adjustment (using lapse rate)
            # For positive temps, the lapse rate still applies
            interpolated_vars['daily_positive_temp'] = station_daily_positive_temp + lapse_rate_temp * (elevation_grid - station_elevation)
            # Ensure non-negative (can't have negative positive degree days)
            interpolated_vars['daily_positive_temp'] = np.maximum(interpolated_vars['daily_positive_temp'], 0)
        
        # Other variables: use constant values from station
        for var_name in ['PDD', 'snowfall_probability']:
            if var_name in station_data:
                interpolated_vars[var_name] = np.full_like(elevation_grid, station_data[var_name])
        
        return interpolated_vars
    
    def predict_spatial_albedo(self, glacier_name, target_date, day_of_year=None):
        """
        Predict albedo across glacier surface using temperature-dominated model
        
        Parameters:
        glacier_name (str): Name of target glacier
        target_date (datetime): Date for prediction
        day_of_year (int): Day of year (calculated if not provided)
        
        Returns:
        numpy.ndarray: Predicted albedo values
        """
        if day_of_year is None:
            day_of_year = target_date.timetuple().tm_yday
        
        print(f"Predicting albedo for {glacier_name} on {target_date.strftime('%Y-%m-%d')}")
        
        # Get interpolated meteorological variables
        met_vars = self.interpolate_meteorological_variables(glacier_name, target_date)
        if met_vars is None:
            print("  Cannot predict: no meteorological data available")
            return None
        
        # Get elevation data
        dem_data = self.dems[glacier_name]
        elevation = dem_data['elevation']
        shape = elevation.shape
        
        # Prepare feature arrays
        features = {
            'day_of_year': np.full(shape, day_of_year),
            'daily_positive_temp': met_vars.get('daily_positive_temp', np.full(shape, np.nan)),
            'PDD': met_vars.get('PDD', np.full(shape, np.nan)),
            'snowfall_probability': met_vars.get('snowfall_probability', np.full(shape, np.nan)),
            'elevation': elevation
        }
        
        # Create feature matrix for valid pixels
        valid_mask = ~np.isnan(elevation)
        if not np.any(valid_mask):
            print("  No valid elevation data")
            return None
        
        # Stack features
        feature_list = []
        for feature_name in self.feature_names:
            if feature_name in features:
                feature_list.append(features[feature_name][valid_mask])
            else:
                print(f"  Warning: Feature {feature_name} not available, using zeros")
                feature_list.append(np.zeros(np.sum(valid_mask)))
        
        feature_stack = np.column_stack(feature_list)
        
        # Apply imputation
        feature_stack_clean = self.imputer.transform(feature_stack)
        
        # Predict albedo
        albedo_values = self.model.predict(feature_stack_clean)
        
        # Create output array
        albedo_predicted = np.full(shape, np.nan)
        albedo_predicted[valid_mask] = albedo_values
        
        # Clip to valid range
        albedo_predicted = np.clip(albedo_predicted, 0, 1)
        
        print(f"  Predicted albedo for {np.sum(valid_mask):,} pixels")
        
        return albedo_predicted
    
    def visualize_spatial_albedo(self, glacier_name, albedo_array, target_date, save_path=None, figsize=(12, 6)):
        """
        Visualize elevation and predicted albedo side-by-side
        """
        dem_data = self.dems[glacier_name]
        elevation = dem_data['elevation']
        
        fig, axes = plt.subplots(1, 2, figsize=figsize)
        
        # Plot 1: Elevation
        im1 = axes[0].imshow(elevation, cmap='terrain', alpha=0.8)
        axes[0].set_title(f'{glacier_name} - Elevation (m)', fontsize=12, fontweight='bold')
        axes[0].set_xlabel('Grid X')
        axes[0].set_ylabel('Grid Y')
        plt.colorbar(im1, ax=axes[0], shrink=0.8, label='Elevation (m)')
        
        # Plot 2: Albedo
        albedo_cmap = LinearSegmentedColormap.from_list(
            'albedo', ['darkblue', 'blue', 'lightblue', 'white'], N=256
        )
        
        im2 = axes[1].imshow(albedo_array, cmap=albedo_cmap, vmin=0, vmax=1)
        axes[1].set_title(f'{glacier_name} - Predicted Albedo (Temp Model)\n{target_date.strftime("%Y-%m-%d")}', 
                         fontsize=12, fontweight='bold')
        axes[1].set_xlabel('Grid X')
        axes[1].set_ylabel('Grid Y')
        plt.colorbar(im2, ax=axes[1], shrink=0.8, label='Albedo')
        
        # Clean appearance
        for ax in axes:
            ax.set_xticks([])
            ax.set_yticks([])
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"  Saved visualization to {save_path}")
        
        plt.show()
        
        # Statistics
        valid_albedo = albedo_array[~np.isnan(albedo_array)]
        if len(valid_albedo) > 0:
            print(f"\nAlbedo Statistics for {glacier_name}:")
            print(f"  Mean: {np.mean(valid_albedo):.2f}")
            print(f"  Std: {np.std(valid_albedo):.2f}")
            print(f"  Range: {np.min(valid_albedo):.2f} - {np.max(valid_albedo):.2f}")
            print(f"  Valid pixels: {len(valid_albedo):,}")
    
    def create_validation_predictions(self, glacier_names=None):
        """
        Create albedo predictions for validation dates
        """
        if glacier_names is None:
            glacier_names = list(self.dems.keys())
        
        validation_dates = [
            datetime(2011, 7, 26),
            datetime(2011, 8, 20)
        ]
        
        results = {}
        
        for date in validation_dates:
            date_str = date.strftime('%Y-%m-%d')
            results[date_str] = {}
            
            print(f"\n=== Processing {date_str} (Temperature Model) ===")
            
            for glacier_name in glacier_names:
                print(f"\nPredicting albedo for {glacier_name}...")
                
                albedo_prediction = self.predict_spatial_albedo(glacier_name, date)
                
                if albedo_prediction is not None:
                    results[date_str][glacier_name] = albedo_prediction
                    
                    save_path = f"{glacier_name}_albedo_prediction_TEMP_{date.strftime('%Y%m%d')}.png"
                    self.visualize_spatial_albedo(
                        glacier_name, 
                        albedo_prediction, 
                        date,
                        save_path=save_path
                    )
                else:
                    print(f"  Failed to predict albedo for {glacier_name} on {date_str}")
        
        return results

def main():
    """
    Main workflow for TEMPERATURE-DOMINATED spatial albedo modeling
    """
    print("=== Spatial Albedo Modeling - TEMPERATURE-DOMINATED MODEL ===\n")
    
    # Define file paths
    dem_paths = {
        'Hansbreen': r"D:\PhD\1st_year\1st_article\DEM\Hansbreen_DEM.tif",
        'Werenskioldbreen': r"D:\PhD\1st_year\1st_article\DEM\Werenskioldbreen_DEM.tif"
    }
    
    aws_data_paths = {
        'hans4': r"C:\Users\PC\PhD\2024_Hans_data\Albedo_Glacier_ML\processed_data\daily_ready\processed_probability\hans4_2011_snowfall_probability_clean.csv",
        'hans9': r"C:\Users\PC\PhD\2024_Hans_data\Albedo_Glacier_ML\processed_data\daily_ready\processed_probability\hans9_2011_snowfall_probability_clean.csv",
        'werenskiold': r"C:\Users\PC\PhD\2024_Hans_data\Albedo_Glacier_ML\processed_data\daily_ready\processed_probability\werenskiold_2011_snowfall_probability_clean.csv"
    }
    
    station_elevations = {
        'hans4': 190,    # AWS_H4
        'hans9': 420,    # AWS_H9
        'werenskiold': 380  # AWS_WRN
    }
    
    # Glacier-specific stations (avoid temperature inversions)
    glacier_to_stations = {
        'Hansbreen': ['hans4'],  # Use only AWS_H4
        'Werenskioldbreen': ['werenskiold']  # Use only AWS_WRN
    }
    
    print("Configuration (Temperature-Dominated Model):")
    print(f"  DEM files: {len(dem_paths)} glaciers")
    print(f"  AWS data: {len(aws_data_paths)} stations")
    print(f"  Glacier-to-station mapping: {glacier_to_stations}")
    print(f"  Model emphasis: Thermal processes (daily_positive_temp, PDD)")
    
    # Initialize model
    spatial_model = SpatialAlbedoModelTemperature(
        dem_paths, aws_data_paths, station_elevations, glacier_to_stations
    )
    
    # Load data
    print("\nLoading DEM and AWS data...")
    spatial_model.load_dems()
    spatial_model.load_aws_data()
    
    # Calculate topographic variables
    print("\nCalculating topographic variables...")
    for glacier_name in dem_paths.keys():
        if glacier_name in spatial_model.dems:
            spatial_model.calculate_topographic_variables(glacier_name)
    
    # Train temperature-dominated model
    print("\nTraining TEMPERATURE-DOMINATED linear regression model...")
    spatial_model.train_model_from_data()
    
    # Create predictions
    print("\nCreating validation predictions...")
    validation_results = spatial_model.create_validation_predictions()
    
    print("\n=== Temperature-Dominated Spatial Modeling Complete ===")
    print("Generated files:")
    print("  - Albedo prediction maps with '_TEMP_' suffix")
    print("  - Temperature-dominated model (emphasizes daily_positive_temp)")
    print("  - Glacier-specific stations (no temperature inversion)")
    
    return spatial_model, validation_results

if __name__ == "__main__":
    model, results = main()
